{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import pandas as pd\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"E:\\Workspace\\Python\\Workspace\\ML_AI\\singular-server-393911-b92f5a618cf9.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequest",
     "evalue": "400 POST https://bigquery.googleapis.com/bigquery/v2/projects/singular-server-393911/jobs?prettyPrint=false: Could not cast literal \"\" to type DATE at [6:39]\n\nLocation: None\nJob ID: c432919f-dc7a-445f-8f98-d36323170b97\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadRequest\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 54\u001b[0m\n\u001b[0;32m     44\u001b[0m df_name \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mEnter the DataFrame name:\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mstrip()\n\u001b[0;32m     47\u001b[0m parameters \u001b[39m=\u001b[39m {\n\u001b[0;32m     48\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcountry\u001b[39m\u001b[39m\"\u001b[39m: country,\n\u001b[0;32m     49\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mstart_date\u001b[39m\u001b[39m\"\u001b[39m: start_date,\n\u001b[0;32m     50\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mend_date\u001b[39m\u001b[39m\"\u001b[39m: end_date\n\u001b[0;32m     51\u001b[0m }\n\u001b[1;32m---> 54\u001b[0m \u001b[39mprint\u001b[39m(estimate_query_size(query,parameters))\n\u001b[0;32m     55\u001b[0m results \u001b[39m=\u001b[39m execute_query(query, parameters)\n\u001b[0;32m     57\u001b[0m \u001b[39mif\u001b[39;00m results:\n",
      "Cell \u001b[1;32mIn[6], line 20\u001b[0m, in \u001b[0;36mestimate_query_size\u001b[1;34m(query, parameters)\u001b[0m\n\u001b[0;32m     18\u001b[0m     query \u001b[39m=\u001b[39m query\u001b[39m.\u001b[39mformat(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparameters)    \n\u001b[0;32m     19\u001b[0m job_config \u001b[39m=\u001b[39m bigquery\u001b[39m.\u001b[39mjob\u001b[39m.\u001b[39mQueryJobConfig(dry_run\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m---> 20\u001b[0m job \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49mquery(query, job_config\u001b[39m=\u001b[39;49mjob_config)\n\u001b[0;32m     21\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEstimated Query size will be: \u001b[39m\u001b[39m{\u001b[39;00mjob\u001b[39m.\u001b[39mtotal_bytes_processed\u001b[39m}\u001b[39;00m\u001b[39m bytes\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\google\\cloud\\bigquery\\client.py:3408\u001b[0m, in \u001b[0;36mClient.query\u001b[1;34m(self, query, job_config, job_id, job_id_prefix, location, project, retry, timeout, job_retry, api_method)\u001b[0m\n\u001b[0;32m   3397\u001b[0m     \u001b[39mreturn\u001b[39;00m _job_helpers\u001b[39m.\u001b[39mquery_jobs_query(\n\u001b[0;32m   3398\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[0;32m   3399\u001b[0m         query,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3405\u001b[0m         job_retry,\n\u001b[0;32m   3406\u001b[0m     )\n\u001b[0;32m   3407\u001b[0m \u001b[39melif\u001b[39;00m api_method \u001b[39m==\u001b[39m enums\u001b[39m.\u001b[39mQueryApiMethod\u001b[39m.\u001b[39mINSERT:\n\u001b[1;32m-> 3408\u001b[0m     \u001b[39mreturn\u001b[39;00m _job_helpers\u001b[39m.\u001b[39;49mquery_jobs_insert(\n\u001b[0;32m   3409\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   3410\u001b[0m         query,\n\u001b[0;32m   3411\u001b[0m         job_config,\n\u001b[0;32m   3412\u001b[0m         job_id,\n\u001b[0;32m   3413\u001b[0m         job_id_prefix,\n\u001b[0;32m   3414\u001b[0m         location,\n\u001b[0;32m   3415\u001b[0m         project,\n\u001b[0;32m   3416\u001b[0m         retry,\n\u001b[0;32m   3417\u001b[0m         timeout,\n\u001b[0;32m   3418\u001b[0m         job_retry,\n\u001b[0;32m   3419\u001b[0m     )\n\u001b[0;32m   3420\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   3421\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGot unexpected value for api_method: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mrepr\u001b[39m(api_method)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\google\\cloud\\bigquery\\_job_helpers.py:114\u001b[0m, in \u001b[0;36mquery_jobs_insert\u001b[1;34m(client, query, job_config, job_id, job_id_prefix, location, project, retry, timeout, job_retry)\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    112\u001b[0m         \u001b[39mreturn\u001b[39;00m query_job\n\u001b[1;32m--> 114\u001b[0m future \u001b[39m=\u001b[39m do_query()\n\u001b[0;32m    115\u001b[0m \u001b[39m# The future might be in a failed state now, but if it's\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[39m# unrecoverable, we'll find out when we ask for it's result, at which\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[39m# point, we may retry.\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m job_id_given:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\google\\cloud\\bigquery\\_job_helpers.py:91\u001b[0m, in \u001b[0;36mquery_jobs_insert.<locals>.do_query\u001b[1;34m()\u001b[0m\n\u001b[0;32m     88\u001b[0m query_job \u001b[39m=\u001b[39m job\u001b[39m.\u001b[39mQueryJob(job_ref, query, client\u001b[39m=\u001b[39mclient, job_config\u001b[39m=\u001b[39mjob_config)\n\u001b[0;32m     90\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 91\u001b[0m     query_job\u001b[39m.\u001b[39;49m_begin(retry\u001b[39m=\u001b[39;49mretry, timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m     92\u001b[0m \u001b[39mexcept\u001b[39;00m core_exceptions\u001b[39m.\u001b[39mConflict \u001b[39mas\u001b[39;00m create_exc:\n\u001b[0;32m     93\u001b[0m     \u001b[39m# The thought is if someone is providing their own job IDs and they get\u001b[39;00m\n\u001b[0;32m     94\u001b[0m     \u001b[39m# their job ID generation wrong, this could end up returning results for\u001b[39;00m\n\u001b[0;32m     95\u001b[0m     \u001b[39m# the wrong query. We thus only try to recover if job ID was not given.\u001b[39;00m\n\u001b[0;32m     96\u001b[0m     \u001b[39mif\u001b[39;00m job_id_given:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\google\\cloud\\bigquery\\job\\query.py:1310\u001b[0m, in \u001b[0;36mQueryJob._begin\u001b[1;34m(self, client, retry, timeout)\u001b[0m\n\u001b[0;32m   1290\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"API call:  begin the job via a POST request\u001b[39;00m\n\u001b[0;32m   1291\u001b[0m \n\u001b[0;32m   1292\u001b[0m \u001b[39mSee\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1306\u001b[0m \u001b[39m    ValueError: If the job has already begun.\u001b[39;00m\n\u001b[0;32m   1307\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1309\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1310\u001b[0m     \u001b[39msuper\u001b[39;49m(QueryJob, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m_begin(client\u001b[39m=\u001b[39;49mclient, retry\u001b[39m=\u001b[39;49mretry, timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m   1311\u001b[0m \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mGoogleAPICallError \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m   1312\u001b[0m     exc\u001b[39m.\u001b[39mmessage \u001b[39m=\u001b[39m _EXCEPTION_FOOTER_TEMPLATE\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   1313\u001b[0m         message\u001b[39m=\u001b[39mexc\u001b[39m.\u001b[39mmessage, location\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlocation, job_id\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjob_id\n\u001b[0;32m   1314\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\google\\cloud\\bigquery\\job\\base.py:693\u001b[0m, in \u001b[0;36m_AsyncJob._begin\u001b[1;34m(self, client, retry, timeout)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[39m# jobs.insert is idempotent because we ensure that every new\u001b[39;00m\n\u001b[0;32m    691\u001b[0m \u001b[39m# job has an ID.\u001b[39;00m\n\u001b[0;32m    692\u001b[0m span_attributes \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mpath\u001b[39m\u001b[39m\"\u001b[39m: path}\n\u001b[1;32m--> 693\u001b[0m api_response \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49m_call_api(\n\u001b[0;32m    694\u001b[0m     retry,\n\u001b[0;32m    695\u001b[0m     span_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mBigQuery.job.begin\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    696\u001b[0m     span_attributes\u001b[39m=\u001b[39;49mspan_attributes,\n\u001b[0;32m    697\u001b[0m     job_ref\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    698\u001b[0m     method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mPOST\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    699\u001b[0m     path\u001b[39m=\u001b[39;49mpath,\n\u001b[0;32m    700\u001b[0m     data\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mto_api_repr(),\n\u001b[0;32m    701\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    702\u001b[0m )\n\u001b[0;32m    703\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_properties(api_response)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\google\\cloud\\bigquery\\client.py:816\u001b[0m, in \u001b[0;36mClient._call_api\u001b[1;34m(self, retry, span_name, span_attributes, job_ref, headers, **kwargs)\u001b[0m\n\u001b[0;32m    812\u001b[0m \u001b[39mif\u001b[39;00m span_name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    813\u001b[0m     \u001b[39mwith\u001b[39;00m create_span(\n\u001b[0;32m    814\u001b[0m         name\u001b[39m=\u001b[39mspan_name, attributes\u001b[39m=\u001b[39mspan_attributes, client\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, job_ref\u001b[39m=\u001b[39mjob_ref\n\u001b[0;32m    815\u001b[0m     ):\n\u001b[1;32m--> 816\u001b[0m         \u001b[39mreturn\u001b[39;00m call()\n\u001b[0;32m    818\u001b[0m \u001b[39mreturn\u001b[39;00m call()\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\google\\api_core\\retry.py:349\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    345\u001b[0m target \u001b[39m=\u001b[39m functools\u001b[39m.\u001b[39mpartial(func, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    346\u001b[0m sleep_generator \u001b[39m=\u001b[39m exponential_sleep_generator(\n\u001b[0;32m    347\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initial, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maximum, multiplier\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_multiplier\n\u001b[0;32m    348\u001b[0m )\n\u001b[1;32m--> 349\u001b[0m \u001b[39mreturn\u001b[39;00m retry_target(\n\u001b[0;32m    350\u001b[0m     target,\n\u001b[0;32m    351\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predicate,\n\u001b[0;32m    352\u001b[0m     sleep_generator,\n\u001b[0;32m    353\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_timeout,\n\u001b[0;32m    354\u001b[0m     on_error\u001b[39m=\u001b[39;49mon_error,\n\u001b[0;32m    355\u001b[0m )\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\google\\api_core\\retry.py:191\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, **kwargs)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[39mfor\u001b[39;00m sleep \u001b[39min\u001b[39;00m sleep_generator:\n\u001b[0;32m    190\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 191\u001b[0m         \u001b[39mreturn\u001b[39;00m target()\n\u001b[0;32m    193\u001b[0m     \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m    194\u001b[0m     \u001b[39m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[0;32m    195\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\google\\cloud\\_http\\__init__.py:494\u001b[0m, in \u001b[0;36mJSONConnection.api_request\u001b[1;34m(self, method, path, query_params, data, content_type, headers, api_base_url, api_version, expect_json, _target_object, timeout, extra_api_info)\u001b[0m\n\u001b[0;32m    482\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_request(\n\u001b[0;32m    483\u001b[0m     method\u001b[39m=\u001b[39mmethod,\n\u001b[0;32m    484\u001b[0m     url\u001b[39m=\u001b[39murl,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m     extra_api_info\u001b[39m=\u001b[39mextra_api_info,\n\u001b[0;32m    491\u001b[0m )\n\u001b[0;32m    493\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mstatus_code \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[1;32m--> 494\u001b[0m     \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mfrom_http_response(response)\n\u001b[0;32m    496\u001b[0m \u001b[39mif\u001b[39;00m expect_json \u001b[39mand\u001b[39;00m response\u001b[39m.\u001b[39mcontent:\n\u001b[0;32m    497\u001b[0m     \u001b[39mreturn\u001b[39;00m response\u001b[39m.\u001b[39mjson()\n",
      "\u001b[1;31mBadRequest\u001b[0m: 400 POST https://bigquery.googleapis.com/bigquery/v2/projects/singular-server-393911/jobs?prettyPrint=false: Could not cast literal \"\" to type DATE at [6:39]\n\nLocation: None\nJob ID: c432919f-dc7a-445f-8f98-d36323170b97\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "client = bigquery.Client()\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "  date, SUM(confirmed) num_reports\n",
    "FROM `bigquery-public-data.covid19_open_data.compatibility_view`\n",
    "WHERE country_region = '{country}'\n",
    "    AND date BETWEEN '{start_date}' AND '{end_date}'\n",
    "GROUP BY date\n",
    "HAVING num_reports IS NOT NULL\n",
    "ORDER BY date ASC\n",
    "\"\"\"\n",
    "\n",
    "#function to estimate the query output's size in bytes\n",
    "def estimate_query_size(query, parameters):\n",
    "    if parameters:\n",
    "        query = query.format(**parameters)    \n",
    "    job_config = bigquery.job.QueryJobConfig(dry_run=True)\n",
    "    job = client.query(query, job_config=job_config)\n",
    "    return f\"Estimated Query size will be: {job.total_bytes_processed} bytes\"\n",
    "\n",
    "\n",
    "def execute_query(query, parameters):\n",
    "    \n",
    "    # Replacing parameter values\n",
    "    if parameters:\n",
    "        query = query.format(**parameters)\n",
    "\n",
    "    query_job = client.query(query)\n",
    "    results = query_job.result()\n",
    "\n",
    "    if results.total_rows == 0:\n",
    "        print(\"Query returns an empty table\")\n",
    "        return None\n",
    "\n",
    "    print(\"Query returns a valid table\")\n",
    "    return results\n",
    "\n",
    "\n",
    "country = input(\"Enter a country name:\").strip()\n",
    "start_date = input(\"Enter the start date (YYYY-MM-DD):\").strip()\n",
    "end_date = input(\"Enter the end date (YYYY-MM-DD):\").strip()\n",
    "df_name = input(\"Enter the DataFrame name:\").strip()\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    \"country\": country,\n",
    "    \"start_date\": start_date,\n",
    "    \"end_date\": end_date\n",
    "}\n",
    "\n",
    "\n",
    "print(estimate_query_size(query,parameters))\n",
    "results = execute_query(query, parameters)\n",
    "\n",
    "if results:\n",
    "    globals()[df_name] = results.to_dataframe()\n",
    "    print(f\"{df_name} DataFrame created successfully.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EDA on covid dataset**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
